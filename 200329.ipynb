{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Open\n",
    "1. Review\n",
    "2. Topic\n",
    "\n",
    "    2.1 Deep Learning 학습방법\n",
    "    \n",
    "    2.2 Keras의 이해\n",
    "    \n",
    "    2.3 MLP 이용 텍스트 분류 실습\n",
    "    \n",
    "3. Q&A\n",
    "4. Next\n",
    "5. Close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 행렬 곱셈을 이용한 순전파(Forward Propagation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인공 신경망은 입력층에서 출력층 방향으로 연산은 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 행렬의 크기 예측\n",
    "\n",
    "- 각 층에 대한 입력과 출력의 개수\n",
    "    * Layer 0 - 입력층 : 입력 4개, 출력 8개\n",
    "    * Layer 1 - 은닉층 1 : 입력 8개, 출력 8개\n",
    "    * Layer 2 - 은닉층 2 : 입력 8개, 출력 3개\n",
    "    * Layer 3 - 출력층 : 입력 3개, 출력 3개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X_(m Ⅹ n) Ⅹ W_(?Ⅹ?) + B_(?Ⅹ?) = Y_(mⅩj)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Layer 1의 행렬 크기 추정\n",
    "    - X 1 x 4 x W ? x ? + B ? x ? = Y m x j: 앞에 1은 배치사이즈, \n",
    "    - X 1 x 4 x W ? x ? + B ? x ? = Y 1 x 8\n",
    "    - X 1 x 4 x W 4 x 8 + B ? x ? = Y 1 x 8\n",
    "    - X 1 x 4 x W 4 x 8 + b 1 x 8 = Y 1 x 8\n",
    "    \n",
    "- Layer 2의 행렬의 크기 추정\n",
    "    - X 1 x 8 x W 8 x 8 + B 1 x 8 = Y 1 x 8\n",
    "\n",
    "- Layer 3의 행렬의 크기 추정\n",
    "    - X 1 x 8 x W 8 x 3 + B 1 x 3 = Y 1 x 3\n",
    "    \n",
    "- 인공 신경망은 입력층에서 은닉층을 지나 출력층에서 예측값을 계산하는 과정을 행렬 연산으로 수행\n",
    "- 학습을 통해 예측값과 실제값으로부터 오차를 계산하고 그 결과로 가중치와 편향 업데이트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 순전파 (Forward Propagation)\n",
    "\n",
    "1. 활성화 함수, 은닉층의 수, 각 은닉층의 뉴런 수 등 DNN 모델을 설제\n",
    "2. 입력값은 입력층, 은닉층을 지나면서 각 층에서 가중치와 함께 연산되며 출력층으로 향한다.\n",
    "3. 출력층에서 모든 연산을 마친 예측값이 나오게 된다.\n",
    "4. 입력층에서 출력층 방향으로 예측값의 연산이 진행되는 과정을 순전파라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실 함수(Loss Function)\n",
    "\n",
    "- 실제값과 예측값의 차이를 계산하는 함수\n",
    "- 오차가 클수록 손실 함수의 값은 크고 오차가 작을수록 손실함수의 값은 작아진다.\n",
    "- 회귀 : 평균 제곱 오차(MSE)\n",
    "- 분류 : 크로스 엔트로피(Cross Entropy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이진 분류 : binary crossentropy\n",
    "- 다중 클래스 분류 : categorical crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "\n",
    "- 손실 함수의 값을 줄여나가면서 학습하는 방법은 어떤 옵티마이저를 사용하느냐에 따라 결정된다.\n",
    "- 배치(Batch) : 가중치 등의 매개변수의 값을 조정하기 위해 사용하는 데이터 양\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배치 경사 하강법(Batch Gradient Descent)\n",
    "\n",
    "- 가장 기본적인 옵티마이저\n",
    "- 오차(loss)를 구할 때 전체 데이터를 고려한다.\n",
    "- 한번의 훈련시 모든 매개 변수 업데이트를 단 한 번 수행하는 옵티마이저\n",
    "- 전체 데이터를 고려해서 학습하므로 epoch(훈련 횟수)당 시간이 오래걸리며, 메모리를 크게 요구하는 단점이 있다.\n",
    "- 글로벌 미니멈을 찾을 수 있다는 장점이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.model.fot(x_train, y_train, batch_size=len(train_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 확률적 경사 하강법(Stochastic Gradient Descent, SGD)\n",
    "- 매개변수 값을 조정 시 전체 데이터가 아니라 랜덤으로 선택한 하나의 데이터에 대해서만 계산하는 방법\n",
    "- 매개변수의 변경 폭이 불안정하고, 때로는 배치 경사 하강법보다 정확도가 낮을 수 있다.\n",
    "- 속도가 빠르다는 장점이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.model.fot(x_train, y_train, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미니 배치 경사 하강법(Mini-Batch Gradient Descent)\n",
    "- 전체 데이터가 아니고, 1개의 데이터도 아니고, 정해진 양에 대해서만 계산하여 매개 변수의 값을 조정하는 경사 하강법\n",
    "- 전체 데이터를 계산하는 것보다는 빠르고, SGD보다 안정적으로 매개변수 변경\n",
    "- 가장 많이 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.model.fit(X_train, y_train, batch_size=32) # 32는 배치의 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모멘텀(Momentum) SGD\n",
    "- 모멘텀은 관성이라는 물리학 법칙을 응용한 방법\n",
    "- 경사 하강법에 관성을 더해준다.\n",
    "- 계산된 접선의 기울기에 한 시점(step) 전의 접선의 기울기 값을 일정한 비율만큼 반영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.optimizer.SGD(lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 아다그라드(Adagrad)\n",
    "\n",
    "- 매개변수는 각자 의미가 다른데 모든 매개변수에 동일한 학습률(learning rate)를 적용하는 것이 비효율적이다.\n",
    "- 아다그라드는 각 매개변수에 서로 다른 학습률을 적용시킨다.\n",
    "- 변화가 많은 매개변수는 학습률을 적게 적용하고, 변화가 적은 매개변수는 학습률을 많이 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.optimizers.Adagrad(lr=0.01, epsilon=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 알엠에스프롭(RMSprop)\n",
    "\n",
    "- 아다그라드는 학습을 계속 진행한 경우에는, 나중에 가서는 학습률이 지나치게 떨어지는 단점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.optimizer.RMSProp(lr=0.001, rho=0.9, epsilon=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam\n",
    "\n",
    "- Adagrad와 RMSProp을 합쳐놓은 optimizer\n",
    "- 방향과 학습률 두가지 문제를 해결할 수 있는 optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.optimizer.Adam(lr=0.001, beta_1=0.0, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- epoch : 전체 데이터에 대해서 순전파와 역전파가 끝난 상태\n",
    "    - 예) 50 에포크 : 전체 데이터 단위로 총 50번 학습을 했다\n",
    "    - 에포크가 너무 지나치거나 너무 모자르면 과적합 또는 과소적합이 발생\n",
    "    \n",
    "- batch size : 몇 개의 데이터 단위로 매개변수를 업데이트 하는지를 말함\n",
    "    - 2000개 데이터에 대해서 200개의 배치 크기를 가지면 배치수는 10이 됨\n",
    "    \n",
    "- iteration : 한 번의 에포크를 끝내기 위해서 필요한 배치 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과적합(Overfitting)을 막는 방법들\n",
    "\n",
    "- 학습 데이터에 모델이 과적합되는 현상은 모델의 성능을 떨어뜨리는 이슈\n",
    "- 모델이 과적합이 되면 훈련 데이터에 대한 정확도는 높을지라도, 새로운 데이터(검증 데이터, 테스트데이터)에 대해서 제대로 작동하지 않는 경우\n",
    "- 모델이 학습 데이터를 불필요할 정도로 과도하게 학습하거나 훈련 데이터에 포함된 노이즈까지 학습한 상태라고 해석할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터의 양을 늘린다.\n",
    "\n",
    "- 데이터양을 늘린다는 것은 데이터의 일반적인 패턴을 학습하여 과적합을 방지\n",
    "- 원래 데이터양이 적을 때에는 의도적으로 기존 데이터를 조금씩 변형하고 추가하여 데이터의 양을 늘리는 방법을 사용하기도 한다. - 데이터 증식 또는 증강(Data Augmentation)\n",
    "- K-fold : 학습 데이터 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 모델의 복잡도 줄이기\n",
    "\n",
    "- 인공 신경망의 복잡도는 은닉층의 수나 매개변수의 수 등으로 결정한다.\n",
    "- 모델 수용력(capacity) : 인공 신경만에서 모델에 있는 매개변수의 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 가중치 규제(Regulation) 적용하기\n",
    "\n",
    "- 복잡한 모델을 좀 더 간단하게 하는 방법으로 가중치 규제\n",
    "    1. L1 규제 : 가중치 w들의 절대값 합계를 비용 함수에 추가한다.(L1 norm), 가중치가 0인 경우가 발생, 가중치가 모델에 영향을 미치는지 대한 유무 확인 -> 어떤 특성들이 모델에 영향을 주고 있는지 정확히 판단하고자 할 때 유용\n",
    "    2. L2 규제 : 모든 가중치 W들의 제곱을 비용 함수에 추가한다.(L2 norm), 가중치가 0에 근접한 값, 어떤 특성들이 모델에 영향을 주고 있는지 정확히 판단이 필요없는 경우 유용, 가중치 감쇠(weight decay) -> 성능이 L1보다는 높다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 드롭아웃(Dropout)\n",
    "- 학습 과정에서 신경망의 일부를 사용하지 않는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, input_shape=(max_words,), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기울기 소실(Gradient Vanishing)과 폭주(Exploding)\n",
    "\n",
    "- 기울기 소실 : 인공 신경망 역전파 과정에서 입력층으로 갈수록 기울기(Gradient)가 점차적으로 작아지는 현상으로 입령층에 가까운 층들에서 가중치 업데이트가 제대로 이루어지지 않으므로 최적의 모델을 찾을 수 없는 현상\n",
    "- 기울기 폭주 : 기울기가 점차 커지더니 가중치들이 비정상적으로 큰 값이 되면서 결국 발산되기도 하는 현상, 주로 RNN(Recurrent Neural Network, RNN)에서 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ReLU와 ReLU 변형 함수 사용\n",
    "\n",
    "- 은닉층에는 시그모이드 함수를 사용하지 않는다.\n",
    "- Leakt ReLU 함수를 사용\n",
    "- 은닉층에는 ReLU나 ReLU 변형 함수 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 그래디언트 클리핑(Gradient Clipping) - 기울기 폭주에 대한 해결\n",
    "\n",
    "- 기울기 값을 자르는 것\n",
    "- 기울기 폭주를 막기 위해 임계값을 넘지 않도록 값을 자른다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.optimizer.Adam(lr=0.0001, clipnorm=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 가중치 초기화(Weight Initialization)\n",
    "\n",
    "- 같은 모델을 훈련시키더라도 가중치가 초기에 어떤 값을 가졌는가에 따라서 모델의 훈련 결과가 달라진다.\n",
    "- 가중치 초기화만 적절히 해줘도 가중치 소실 문제를 해결(완화)할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 가비어 초기화(Xavier Initialization) or 글로럿 초기화(Glorot Initialization)\n",
    "\n",
    "- 균등분포 또는 정규 분포를 이용하여 초기화\n",
    "- 여러 층의 기울기 분산 사이에 균형을 맞춰서 특정 층이 너무 주목을 받거나 다른 층이 뒤쳐지는 것을 막는다.\n",
    "- 시그모이드 함수나 하이퍼볼릭 탄젠트 함수와 같은 S자 형태인 활성화 함수와 함께 사용할 경우에는 좋은 성능을 보이나 ReLU와 함께 사용하면 성능이 좋지 않다.\n",
    "\n",
    "#### He 초기화(He Initialization)\n",
    "\n",
    "- 정규 분포와 균등 분포 두 가지로 나누어 적용\n",
    "- He 초기화는 가이버 초기화와 다르게 다음 층의 뉴런의 수를 반영하지 않는다.\n",
    "- ReLU 계열 함수를 사용할 경우 효율적\n",
    "\n",
    "#### 가중치 초기화 방법 : ReLU 함수 + He 초기화 방법이 가장 보편적인 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 배치 정규화 방법\n",
    "### 층 정규화 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras\n",
    "\n",
    "- Keras는 오픈소스 기반의 인공신경망 파이썬 프레임워크 라이브러리\n",
    "- Tensorflow의 상위 레벨 인터페이스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 전처리(Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_text = \"The earth is an awesome place live\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.fit_on_texts([fit_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"The earth is an great place live\"\n",
    "sequences = t.texts_to_sequences([test_text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences : [1, 2, 3, 4, 6, 7]\n",
      "word index : {'the': 1, 'earth': 2, 'is': 3, 'an': 4, 'awesome': 5, 'place': 6, 'live': 7}\n"
     ]
    }
   ],
   "source": [
    "print(\"sequences :\", sequences)\n",
    "print(\"word index :\", t.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pad_sequences() : 모델의 입력으로 사용하려는 모든 샘플 데이터의 길이를 동일하게 맞추기 위하여 패딩(padding) 작업을 수행하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [0, 7, 6]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sequences([[1, 2, 3], [3, 4, 5, 6], [7, 6]], maxlen=3, padding='pre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 첫번쩨 인수 : padding을 진행할 데이터\n",
    "- maxlen : 모든 데이터에 대해서 정규화 할 길이\n",
    "- padding : 'pre'-앞에 0을 채우고, 'post'-뒤에 0을 채움"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 워드 임베딩(Word Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 모델링(Modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential() : 인공 신경망에서 층을 구성할 때 사용하는 객체, 이를 이용하여 model을 생성한 후 model.add()로 Layer를 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model.add() # 입력층\n",
    "# model.add() # 은닉층\n",
    "# model.add() # 출력층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Embedding()을 통해 생성하는 임베딩 층(Embedded layer)를 추가할 수 있다\n",
    "- Dense() : 전결합층(Fully-Connected layer)을 추가하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(vocabulary, output_dim, input_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model.add(Dense(1, input_dim=3, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 첫번째 인수 : 출력 뉴런 수\n",
    "- input_dim = 입력 뉴런 수(입력 차원)\n",
    "- activation = 활성화 함수\n",
    "    - linear : default, 활성화 함수 없이 가중치 계산 결과 그대로 출력, 회귀 문제\n",
    "    - sigmoid : 시그모이드 함수, 이진 분류 문제\n",
    "    - softmax : 소프트맥스 함수, 다중 클래스 분류 문제\n",
    "    - relu : ReLU 함수, 은닉층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 49\n",
      "Trainable params: 49\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 컴파일(Compile)과 훈련(Training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 평가(Evaluation)와 예측(Prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 모델 저장(Save)와 로드(Load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras 함수형 API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP를 이용한 텍스트 분류 - Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"먹고 싶은 사과\", \"먹고 싶은 바나나\", \"길고 노란 바나나\", \"저는 과일이 좋아요\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'먹고': 1, '싶은': 2, '바나나': 3, '사과': 4, '길고': 5, '노란': 6, '저는': 7, '과일이': 8, '좋아요': 9}\n"
     ]
    }
   ],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(text)\n",
    "print(t.word_index) # 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(t.texts_to_matrix(text, mode='count')) # DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(t.texts_to_matrix(text, mode='binary')) # 해당 단어의 존재 유무만 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.85 0.85 0.   1.1  0.   0.   0.   0.   0.  ]\n",
      " [0.   0.85 0.85 0.85 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.85 0.   1.1  1.1  0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   1.1  1.1  1.1 ]]\n"
     ]
    }
   ],
   "source": [
    "print(t.texts_to_matrix(text, mode='tfidf').round(2)) # TF-IDF matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.33 0.33 0.   0.33 0.   0.   0.   0.   0.  ]\n",
      " [0.   0.33 0.33 0.33 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.33 0.   0.33 0.33 0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.33 0.33 0.33]]\n"
     ]
    }
   ],
   "source": [
    "print(t.texts_to_matrix(text, mode='freq').round(2)) # 각 문서에서 각 단어의 등장 횟수를 분자로, 각 문서의 크기(전체 단어 총 합)를 분모로 한 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20개 뉴스 그룹에 대한 테스트 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsdata = fetch_20newsgroups(subset='train') # 'train'을 기재하면 훈련 data만 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "print(newsdata.keys()) # data - text 내용, target - 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 데이터 개수 : 11314\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련용 데이터 개수 : {}\".format(len(newsdata.data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 주제 개수 :20\n",
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(\"총 주제 개수 :{}\".format(len(newsdata.target_names)))\n",
    "print(newsdata.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫번째 샘플의 레이블: 7\n"
     ]
    }
   ],
   "source": [
    "print(\"첫번째 샘플의 레이블: {}\".format(newsdata.target[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7번째 레이블이 의미하는 주제 : rec.autos\n"
     ]
    }
   ],
   "source": [
    "print(\"7번째 레이블이 의미하는 주제 : {}\".format(newsdata.target_names[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               email  target\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...       7\n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...       4\n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4\n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1\n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(newsdata.data, columns=['email'])\n",
    "data['target'] = pd.Series(newsdata.target)\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11314 entries, 0 to 11313\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   email   11314 non-null  object\n",
      " 1   target  11314 non-null  int32 \n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 132.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복을 제외한 샘플 수 : 11314\n",
      "중복을 제외한 타겟 수 : 20\n"
     ]
    }
   ],
   "source": [
    "print(\"중복을 제외한 샘플 수 : {}\".format(len(data['email'].unique())))\n",
    "print(\"중복을 제외한 타겟 수 : {}\".format(len(data['target'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2174949efc8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['target'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    target  count\n",
      "0        0    480\n",
      "1        1    584\n",
      "2        2    591\n",
      "3        3    590\n",
      "4        4    578\n",
      "5        5    593\n",
      "6        6    585\n",
      "7        7    594\n",
      "8        8    598\n",
      "9        9    597\n",
      "10      10    600\n",
      "11      11    595\n",
      "12      12    591\n",
      "13      13    594\n",
      "14      14    593\n",
      "15      15    599\n",
      "16      16    546\n",
      "17      17    564\n",
      "18      18    465\n",
      "19      19    377\n"
     ]
    }
   ],
   "source": [
    "print(data.groupby('target').size().reset_index(name='count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 데이터와 테스트 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsdata_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "train_email = data['email']\n",
    "train_label = data['target']\n",
    "test_email = newsdata_test.data\n",
    "test_label = newsdata_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 10000\n",
    "num_classes = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(train_data, test_data, mode):\n",
    "    t = Tokenizer(num_words = num_words)\n",
    "    t.fit_on_texts(train_data)\n",
    "    X_train = t.texts_to_matrix(train_data, mode=mode)\n",
    "    X_test = t.texts_to_matrix(test_data, mode=mode)\n",
    "    \n",
    "    return X_train, X_test, t.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, index_to_word = prepare_data(train_email, test_email, 'binary')\n",
    "y_train = to_categorical(train_label, num_classes)\n",
    "y_test = to_categorical(test_label, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 본문의 크기 : (11314, 10000)\n",
      "테스트 샘플 본문의 크기 : (7532, 10000)\n",
      "훈련 샘플 레이블의 크기 : (11314, 20)\n",
      "테스트 샘플 레이블의 크기 : (7532, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 샘플 본문의 크기 : {}\".format(X_train.shape))\n",
    "print(\"테스트 샘플 본문의 크기 : {}\".format(X_test.shape))\n",
    "print(\"훈련 샘플 레이블의 크기 : {}\".format(y_train.shape))\n",
    "print(\"테스트 샘플 레이블의 크기 : {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP를 사용하여 텍스트 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP 모델 설계\n",
    "def fit_and_evaluate(X_train, y_train, X_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_shape =(num_words,), activation='relu') )\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=128, epochs=5, verbose=1, validation_split=0.1)\n",
    "    score = model.evaluate(X_test, y_test, batch_size=128, verbose=0)\n",
    "    \n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10182 samples, validate on 1132 samples\n",
      "Epoch 1/5\n",
      "10182/10182 [==============================] - 4s 384us/sample - loss: 2.2349 - accuracy: 0.3441 - val_loss: 0.9278 - val_accuracy: 0.8198\n",
      "Epoch 2/5\n",
      "10182/10182 [==============================] - 3s 298us/sample - loss: 0.8701 - accuracy: 0.7606 - val_loss: 0.4610 - val_accuracy: 0.8790\n",
      "Epoch 3/5\n",
      "10182/10182 [==============================] - 3s 307us/sample - loss: 0.4354 - accuracy: 0.8836 - val_loss: 0.3412 - val_accuracy: 0.9055\n",
      "Epoch 4/5\n",
      "10182/10182 [==============================] - 3s 297us/sample - loss: 0.2586 - accuracy: 0.9334 - val_loss: 0.3089 - val_accuracy: 0.9099\n",
      "Epoch 5/5\n",
      "10182/10182 [==============================] - 3s 292us/sample - loss: 0.1754 - accuracy: 0.9569 - val_loss: 0.2971 - val_accuracy: 0.9134\n",
      "Train on 10182 samples, validate on 1132 samples\n",
      "Epoch 1/5\n",
      "10182/10182 [==============================] - 4s 437us/sample - loss: 2.7829 - accuracy: 0.2489 - val_loss: 1.5896 - val_accuracy: 0.7509\n",
      "Epoch 2/5\n",
      "10182/10182 [==============================] - 3s 323us/sample - loss: 1.4215 - accuracy: 0.6380 - val_loss: 0.7237 - val_accuracy: 0.8472\n",
      "Epoch 3/5\n",
      "10182/10182 [==============================] - 3s 313us/sample - loss: 0.8117 - accuracy: 0.7975 - val_loss: 0.5298 - val_accuracy: 0.8781\n",
      "Epoch 4/5\n",
      "10182/10182 [==============================] - 3s 300us/sample - loss: 0.5319 - accuracy: 0.8723 - val_loss: 0.4528 - val_accuracy: 0.8975\n",
      "Epoch 5/5\n",
      "10182/10182 [==============================] - 3s 285us/sample - loss: 0.3890 - accuracy: 0.9103 - val_loss: 0.4466 - val_accuracy: 0.8878\n",
      "Train on 10182 samples, validate on 1132 samples\n",
      "Epoch 1/5\n",
      "10182/10182 [==============================] - 4s 380us/sample - loss: 2.2678 - accuracy: 0.3572 - val_loss: 0.7871 - val_accuracy: 0.8445\n",
      "Epoch 2/5\n",
      "10182/10182 [==============================] - 3s 287us/sample - loss: 0.8378 - accuracy: 0.7733 - val_loss: 0.4453 - val_accuracy: 0.8940\n",
      "Epoch 3/5\n",
      "10182/10182 [==============================] - 3s 282us/sample - loss: 0.4802 - accuracy: 0.8823 - val_loss: 0.3405 - val_accuracy: 0.9055\n",
      "Epoch 4/5\n",
      "10182/10182 [==============================] - 3s 286us/sample - loss: 0.2893 - accuracy: 0.9273 - val_loss: 0.3295 - val_accuracy: 0.9099\n",
      "Epoch 5/5\n",
      "10182/10182 [==============================] - 3s 290us/sample - loss: 0.2184 - accuracy: 0.9497 - val_loss: 0.3109 - val_accuracy: 0.9187\n",
      "Train on 10182 samples, validate on 1132 samples\n",
      "Epoch 1/5\n",
      "10182/10182 [==============================] - 4s 419us/sample - loss: 2.9784 - accuracy: 0.0822 - val_loss: 2.9294 - val_accuracy: 0.3701\n",
      "Epoch 2/5\n",
      "10182/10182 [==============================] - 4s 345us/sample - loss: 2.7218 - accuracy: 0.2254 - val_loss: 2.3767 - val_accuracy: 0.4143\n",
      "Epoch 3/5\n",
      "10182/10182 [==============================] - 3s 340us/sample - loss: 2.1705 - accuracy: 0.3189 - val_loss: 1.8692 - val_accuracy: 0.5212\n",
      "Epoch 4/5\n",
      "10182/10182 [==============================] - 3s 339us/sample - loss: 1.7395 - accuracy: 0.4504 - val_loss: 1.4886 - val_accuracy: 0.6148ac\n",
      "Epoch 5/5\n",
      "10182/10182 [==============================] - 3s 332us/sample - loss: 1.4189 - accuracy: 0.5624 - val_loss: 1.2052 - val_accuracy: 0.7191\n"
     ]
    }
   ],
   "source": [
    "modes = ['binary', 'count', 'tfidf', 'freq']\n",
    "\n",
    "for mode in modes:\n",
    "    X_train, X_test, _ = prepare_data(train_email, test_email, mode)\n",
    "    score = fit_and_evaluate(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
