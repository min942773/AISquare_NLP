{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Open\n",
    "1. Review\n",
    "2. Topic\n",
    "    \n",
    "    2.1 워드 임베딩( Word Embedding )\n",
    "    \n",
    "    2.2 Word2Vec\n",
    "        \n",
    "        \n",
    "3. Q & A\n",
    "4. Next\n",
    "5. Close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 글자 단위 RNN( Char RNN )으로 텍스트 생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 이해 및 전처리\n",
    "\n",
    "다 대 일( many-to-one ) 구조 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "I get on with life as a programmer,\n",
    "I like to contemplate beer.\n",
    "But when I start to daydream,\n",
    "My mind turns straight to wine.\n",
    "\n",
    "Do I love wine more than beer?\n",
    "\n",
    "I like to use words about beer.\n",
    "But when I stop my talking,\n",
    "My mind turns straight to wine.\n",
    "\n",
    "I hate bugs and errors.\n",
    "But I just think back to wine,\n",
    "And I'm happy once again.\n",
    "\n",
    "I like to hang out with programming and deep learning.\n",
    "But when left alone,\n",
    "My mind turns straight to wine.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I get on with life as a programmer, I like to contemplate beer. But when I start to daydream, My mind turns straight to wine. Do I love wine more than beer? I like to use words about beer. But when I stop my talking, My mind turns straight to wine. I hate bugs and errors. But I just think back to wine, And I'm happy once again. I like to hang out with programming and deep learning. But when left alone, My mind turns straight to wine.\n"
     ]
    }
   ],
   "source": [
    "tokens = text.split()\n",
    "text = ' '.join( tokens )\n",
    "print( text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', \"'\", ',', '.', '?', 'A', 'B', 'D', 'I', 'M', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y']\n"
     ]
    }
   ],
   "source": [
    "char_vocab = sorted( list( set( text ) ) )\n",
    "print( char_vocab )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "글자 집합 크기 : 33\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len( char_vocab )\n",
    "print( '글자 집합 크기 : {}'.format( vocab_size ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, \"'\": 1, ',': 2, '.': 3, '?': 4, 'A': 5, 'B': 6, 'D': 7, 'I': 8, 'M': 9, 'a': 10, 'b': 11, 'c': 12, 'd': 13, 'e': 14, 'f': 15, 'g': 16, 'h': 17, 'i': 18, 'j': 19, 'k': 20, 'l': 21, 'm': 22, 'n': 23, 'o': 24, 'p': 25, 'r': 26, 's': 27, 't': 28, 'u': 29, 'v': 30, 'w': 31, 'y': 32}\n"
     ]
    }
   ],
   "source": [
    "char_to_index = dict( ( c, i ) for i, c in enumerate( char_vocab ) )\n",
    "print( char_to_index )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 훈련 샘플 수 : 426\n"
     ]
    }
   ],
   "source": [
    "length = 11\n",
    "sequences = []\n",
    "for i in range( length, len( text ) ):\n",
    "    seq = text[ i - length:i ]\n",
    "    sequences.append( seq )\n",
    "print( '총 훈련 샘플 수 : {}'.format( len( sequences ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I get on wi',\n",
       " ' get on wit',\n",
       " 'get on with',\n",
       " 'et on with ',\n",
       " 't on with l',\n",
       " ' on with li',\n",
       " 'on with lif',\n",
       " 'n with life',\n",
       " ' with life ',\n",
       " 'with life a']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[ :10 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩\n",
    "X = []\n",
    "for line in sequences:\n",
    "    temp_X = [ char_to_index[ char ] for char in line ]\n",
    "    X.append( temp_X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 글자 집합과 예측 글자 분리\n",
    "sequences = np.array( X )\n",
    "X = sequences[ :, :-1 ] # 글자 집합\n",
    "y = sequences[ :, -1 ] # 다음 예측 글자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  0 16 14 28  0 24 23  0 31]\n",
      "[ 0 16 14 28  0 24 23  0 31 18]\n",
      "[16 14 28  0 24 23  0 31 18 28]\n",
      "[14 28  0 24 23  0 31 18 28 17]\n",
      "[28  0 24 23  0 31 18 28 17  0]\n"
     ]
    }
   ],
   "source": [
    "for line in X[ :5 ]:\n",
    "    print( line )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [ to_categorical( x, num_classes = vocab_size ) for x in X ]\n",
    "X = np.array( sequences )\n",
    "y = to_categorical( y, num_classes = vocab_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 10, 33)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add( LSTM( 80, input_shape = ( X.shape[ 1 ], X.shape[ 2 ] ) ) )\n",
    "model.add( Dense( vocab_size, activation = 'softmax' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426 samples\n",
      "Epoch 1/100\n",
      "426/426 - 2s - loss: 3.4648 - accuracy: 0.0822\n",
      "Epoch 2/100\n",
      "426/426 - 0s - loss: 3.3191 - accuracy: 0.1925\n",
      "Epoch 3/100\n",
      "426/426 - 0s - loss: 3.0471 - accuracy: 0.1972\n",
      "Epoch 4/100\n",
      "426/426 - 0s - loss: 2.9764 - accuracy: 0.1972\n",
      "Epoch 5/100\n",
      "426/426 - 0s - loss: 2.9538 - accuracy: 0.1972\n",
      "Epoch 6/100\n",
      "426/426 - 0s - loss: 2.9224 - accuracy: 0.1972\n",
      "Epoch 7/100\n",
      "426/426 - 0s - loss: 2.8998 - accuracy: 0.1972\n",
      "Epoch 8/100\n",
      "426/426 - 0s - loss: 2.8845 - accuracy: 0.1972\n",
      "Epoch 9/100\n",
      "426/426 - 0s - loss: 2.8659 - accuracy: 0.1972\n",
      "Epoch 10/100\n",
      "426/426 - 0s - loss: 2.8344 - accuracy: 0.1972\n",
      "Epoch 11/100\n",
      "426/426 - 0s - loss: 2.7918 - accuracy: 0.1972\n",
      "Epoch 12/100\n",
      "426/426 - 0s - loss: 2.7509 - accuracy: 0.1995\n",
      "Epoch 13/100\n",
      "426/426 - 0s - loss: 2.7119 - accuracy: 0.2277\n",
      "Epoch 14/100\n",
      "426/426 - 0s - loss: 2.6543 - accuracy: 0.2207\n",
      "Epoch 15/100\n",
      "426/426 - 0s - loss: 2.6017 - accuracy: 0.2207\n",
      "Epoch 16/100\n",
      "426/426 - 0s - loss: 2.5415 - accuracy: 0.2676\n",
      "Epoch 17/100\n",
      "426/426 - 0s - loss: 2.5095 - accuracy: 0.3122\n",
      "Epoch 18/100\n",
      "426/426 - 0s - loss: 2.4447 - accuracy: 0.3169\n",
      "Epoch 19/100\n",
      "426/426 - 0s - loss: 2.4114 - accuracy: 0.3052\n",
      "Epoch 20/100\n",
      "426/426 - 0s - loss: 2.3442 - accuracy: 0.2981\n",
      "Epoch 21/100\n",
      "426/426 - 0s - loss: 2.2817 - accuracy: 0.3545\n",
      "Epoch 22/100\n",
      "426/426 - 0s - loss: 2.2236 - accuracy: 0.3756\n",
      "Epoch 23/100\n",
      "426/426 - 0s - loss: 2.1692 - accuracy: 0.4061\n",
      "Epoch 24/100\n",
      "426/426 - 0s - loss: 2.1185 - accuracy: 0.4249\n",
      "Epoch 25/100\n",
      "426/426 - 0s - loss: 2.0900 - accuracy: 0.3991\n",
      "Epoch 26/100\n",
      "426/426 - 0s - loss: 2.0493 - accuracy: 0.4484\n",
      "Epoch 27/100\n",
      "426/426 - 0s - loss: 1.9973 - accuracy: 0.4319\n",
      "Epoch 28/100\n",
      "426/426 - 0s - loss: 1.9410 - accuracy: 0.4718\n",
      "Epoch 29/100\n",
      "426/426 - 0s - loss: 1.8929 - accuracy: 0.4695\n",
      "Epoch 30/100\n",
      "426/426 - 0s - loss: 1.8429 - accuracy: 0.4953\n",
      "Epoch 31/100\n",
      "426/426 - 0s - loss: 1.7832 - accuracy: 0.4718\n",
      "Epoch 32/100\n",
      "426/426 - 0s - loss: 1.7445 - accuracy: 0.5399\n",
      "Epoch 33/100\n",
      "426/426 - 0s - loss: 1.7113 - accuracy: 0.5117\n",
      "Epoch 34/100\n",
      "426/426 - 0s - loss: 1.6560 - accuracy: 0.5587\n",
      "Epoch 35/100\n",
      "426/426 - 0s - loss: 1.6185 - accuracy: 0.5915\n",
      "Epoch 36/100\n",
      "426/426 - 0s - loss: 1.6006 - accuracy: 0.5775\n",
      "Epoch 37/100\n",
      "426/426 - 0s - loss: 1.5388 - accuracy: 0.6056\n",
      "Epoch 38/100\n",
      "426/426 - 0s - loss: 1.4853 - accuracy: 0.5962\n",
      "Epoch 39/100\n",
      "426/426 - 0s - loss: 1.4448 - accuracy: 0.6150\n",
      "Epoch 40/100\n",
      "426/426 - 0s - loss: 1.4122 - accuracy: 0.6338\n",
      "Epoch 41/100\n",
      "426/426 - 0s - loss: 1.3802 - accuracy: 0.6362\n",
      "Epoch 42/100\n",
      "426/426 - 0s - loss: 1.3556 - accuracy: 0.6479\n",
      "Epoch 43/100\n",
      "426/426 - 0s - loss: 1.2999 - accuracy: 0.6784\n",
      "Epoch 44/100\n",
      "426/426 - 0s - loss: 1.2653 - accuracy: 0.6620\n",
      "Epoch 45/100\n",
      "426/426 - 0s - loss: 1.2128 - accuracy: 0.7113\n",
      "Epoch 46/100\n",
      "426/426 - 0s - loss: 1.1928 - accuracy: 0.7136\n",
      "Epoch 47/100\n",
      "426/426 - 0s - loss: 1.1436 - accuracy: 0.7207\n",
      "Epoch 48/100\n",
      "426/426 - 0s - loss: 1.1168 - accuracy: 0.7183\n",
      "Epoch 49/100\n",
      "426/426 - 0s - loss: 1.0645 - accuracy: 0.7606\n",
      "Epoch 50/100\n",
      "426/426 - 0s - loss: 1.0366 - accuracy: 0.7512\n",
      "Epoch 51/100\n",
      "426/426 - 0s - loss: 0.9928 - accuracy: 0.7653\n",
      "Epoch 52/100\n",
      "426/426 - 0s - loss: 0.9652 - accuracy: 0.7723\n",
      "Epoch 53/100\n",
      "426/426 - 0s - loss: 0.9380 - accuracy: 0.7817\n",
      "Epoch 54/100\n",
      "426/426 - 0s - loss: 0.9012 - accuracy: 0.8099\n",
      "Epoch 55/100\n",
      "426/426 - 0s - loss: 0.8797 - accuracy: 0.8005\n",
      "Epoch 56/100\n",
      "426/426 - 0s - loss: 0.8403 - accuracy: 0.8122\n",
      "Epoch 57/100\n",
      "426/426 - 0s - loss: 0.8161 - accuracy: 0.8169\n",
      "Epoch 58/100\n",
      "426/426 - 0s - loss: 0.8089 - accuracy: 0.8052\n",
      "Epoch 59/100\n",
      "426/426 - 0s - loss: 0.7875 - accuracy: 0.8263\n",
      "Epoch 60/100\n",
      "426/426 - 0s - loss: 0.7485 - accuracy: 0.8404\n",
      "Epoch 61/100\n",
      "426/426 - 0s - loss: 0.7316 - accuracy: 0.8380\n",
      "Epoch 62/100\n",
      "426/426 - 0s - loss: 0.6791 - accuracy: 0.8662\n",
      "Epoch 63/100\n",
      "426/426 - 0s - loss: 0.6678 - accuracy: 0.8568\n",
      "Epoch 64/100\n",
      "426/426 - 0s - loss: 0.6324 - accuracy: 0.8732\n",
      "Epoch 65/100\n",
      "426/426 - 0s - loss: 0.6188 - accuracy: 0.8803\n",
      "Epoch 66/100\n",
      "426/426 - 0s - loss: 0.5856 - accuracy: 0.8850\n",
      "Epoch 67/100\n",
      "426/426 - 0s - loss: 0.5543 - accuracy: 0.8991\n",
      "Epoch 68/100\n",
      "426/426 - 0s - loss: 0.5408 - accuracy: 0.9085\n",
      "Epoch 69/100\n",
      "426/426 - 0s - loss: 0.5072 - accuracy: 0.9249\n",
      "Epoch 70/100\n",
      "426/426 - 0s - loss: 0.4945 - accuracy: 0.9155\n",
      "Epoch 71/100\n",
      "426/426 - 0s - loss: 0.4729 - accuracy: 0.9366\n",
      "Epoch 72/100\n",
      "426/426 - 0s - loss: 0.4579 - accuracy: 0.9366\n",
      "Epoch 73/100\n",
      "426/426 - 0s - loss: 0.4450 - accuracy: 0.9437\n",
      "Epoch 74/100\n",
      "426/426 - 0s - loss: 0.4259 - accuracy: 0.9413\n",
      "Epoch 75/100\n",
      "426/426 - 0s - loss: 0.4178 - accuracy: 0.9484\n",
      "Epoch 76/100\n",
      "426/426 - 0s - loss: 0.3903 - accuracy: 0.9507\n",
      "Epoch 77/100\n",
      "426/426 - 0s - loss: 0.3961 - accuracy: 0.9460\n",
      "Epoch 78/100\n",
      "426/426 - 0s - loss: 0.3681 - accuracy: 0.9601\n",
      "Epoch 79/100\n",
      "426/426 - 0s - loss: 0.3562 - accuracy: 0.9624\n",
      "Epoch 80/100\n",
      "426/426 - 0s - loss: 0.3517 - accuracy: 0.9601\n",
      "Epoch 81/100\n",
      "426/426 - 0s - loss: 0.3410 - accuracy: 0.9671\n",
      "Epoch 82/100\n",
      "426/426 - 0s - loss: 0.3226 - accuracy: 0.9671\n",
      "Epoch 83/100\n",
      "426/426 - 0s - loss: 0.3058 - accuracy: 0.9671\n",
      "Epoch 84/100\n",
      "426/426 - 0s - loss: 0.2926 - accuracy: 0.9789\n",
      "Epoch 85/100\n",
      "426/426 - 0s - loss: 0.2830 - accuracy: 0.9765\n",
      "Epoch 86/100\n",
      "426/426 - 0s - loss: 0.2718 - accuracy: 0.9765\n",
      "Epoch 87/100\n",
      "426/426 - 0s - loss: 0.2603 - accuracy: 0.9765\n",
      "Epoch 88/100\n",
      "426/426 - 0s - loss: 0.2514 - accuracy: 0.9742\n",
      "Epoch 89/100\n",
      "426/426 - 0s - loss: 0.2434 - accuracy: 0.9742\n",
      "Epoch 90/100\n",
      "426/426 - 0s - loss: 0.2332 - accuracy: 0.9836\n",
      "Epoch 91/100\n",
      "426/426 - 0s - loss: 0.2215 - accuracy: 0.9836\n",
      "Epoch 92/100\n",
      "426/426 - 0s - loss: 0.2179 - accuracy: 0.9812\n",
      "Epoch 93/100\n",
      "426/426 - 0s - loss: 0.2102 - accuracy: 0.9812\n",
      "Epoch 94/100\n",
      "426/426 - 0s - loss: 0.2007 - accuracy: 0.9789\n",
      "Epoch 95/100\n",
      "426/426 - 0s - loss: 0.1984 - accuracy: 0.9812\n",
      "Epoch 96/100\n",
      "426/426 - 0s - loss: 0.1998 - accuracy: 0.9765\n",
      "Epoch 97/100\n",
      "426/426 - 0s - loss: 0.1927 - accuracy: 0.9812\n",
      "Epoch 98/100\n",
      "426/426 - 0s - loss: 0.1892 - accuracy: 0.9789\n",
      "Epoch 99/100\n",
      "426/426 - 0s - loss: 0.1980 - accuracy: 0.9812\n",
      "Epoch 100/100\n",
      "426/426 - 0s - loss: 0.1783 - accuracy: 0.9789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fe4efbdec8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile( loss = 'categorical_crossentropy', optimizer = 'adam', metrics = [ 'accuracy' ] )\n",
    "model.fit( X, y, epochs = 100, verbose = 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation( model, char_to_index, seq_length, seed_text, n ):\n",
    "    init_text = seed_text\n",
    "    sentence = ''\n",
    "    for _ in range( n ):\n",
    "        encoded = [ char_to_index[ char ] for char in seed_text ]\n",
    "        encoded = pad_sequences( [ encoded ], maxlen = seq_length, padding = 'pre' )\n",
    "        encoded = to_categorical( encoded, num_classes = len( char_to_index ) )\n",
    "        result = model.predict_classes( encoded, verbose = 0 )\n",
    "        for char, index in char_to_index.items():\n",
    "            if index == result:\n",
    "                break\n",
    "        seed_text = seed_text + char\n",
    "        sentence = sentence + char\n",
    "    sentence = init_text + sentence\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I got on with life as a programmer, I like to hang out with programming and deep learning.\n"
     ]
    }
   ],
   "source": [
    "print( sentence_generation( model, char_to_index, 10, 'I got on w', 80 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 워드 임베딩(Word Embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 희소 표현(Sparse Representation)\n",
    "\n",
    "- 하나의 값만 1로 표현하고 나머지는 모두 0으로 표현\n",
    "- 희소 벡터 ex) 10차원 vector : apple [1 0 0 0 0 0 0 0 0 0]\n",
    "- 단점\n",
    "    1. 기억장소 낭비 요인 발생\n",
    "    2. 단어의 의미 표현이 불가능\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 밀집 표현(Dense Representation)\n",
    "\n",
    "- 벡터의 차원을 단어 집합의 크기로 정하지 않고 사용자가 설정한 크기로 설정한 후 단어를 표현\n",
    "- 밀집 벡터(dense vector) : 사용자가 임의로 벡터의 크기를 결정하고 실수로 표현\n",
    "- 워드 임베딩(word embedding) : 단어를 밀집 벡터의 형태로 표현하는 방법\n",
    "- 임베딩 벡터(embedding vector) : 밀집 벡터를 워드 임베딩 과정을 통해 나온 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||원-핫벡터|임베딩벡터|\n",
    "|---|---|---|\n",
    "|차원|고차원(단어 집합 크기)|저차원|\n",
    "|다른 표현|희소 벡터의 일종|밀집 벡터의 일종|\n",
    "|표현 방법|수동|훈련 데이터로 학습|\n",
    "|값의 타입|1 또는 0|실수|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec\n",
    "\n",
    "분산 표현(distributed Representation)\n",
    "\n",
    "- 단어의 의미를 다차원 공간에 벡터화하여 표현하는 방법\n",
    "- 분산 표현은 분포 가설(distributional hypothesis)라는 가정 하에 만들어진 표현 방법\n",
    "- 분포 가설은 '비슷한 위치에서 등장하는 단어들은 비슷한 의미를 가진다'라는 가정\n",
    "- 임베딩 벡터를 이용하여 저차원에 단어의 의미를 여러 차원에다가 분사하여 표현\n",
    "- 분산 표현 방법을 이용하여 단어 간 유사도를 계산할 수 있다.\n",
    "- 분산 표현 학습 방법으로 NNLM, RNNLM을 사용하나 속도를 개선시킨 Word2Vec를 근래는 많이 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec은 분산표현 방식으로 단어의 의미를 기반으로 단어 예측하는 알고리즘(모델)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec 종류\n",
    "\n",
    "- CBOW(Continuous Bag of Words) : 주변에 있는 단어들을 가지고, 중간에 있는 단어들을 예측하는 방법\n",
    "- Skip-Gram : 중간에 있는 단어로 주변 단어들을 예측하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CBOW 이해\n",
    "\n",
    "예문 : \"The fat cat sat on the mat\"\n",
    "\n",
    "예측 : \"The fat cat [...] on the mat\"\n",
    "\n",
    "'sat'을 예측하는 경우 'sat'의 주변 단어(앞과 뒤의 단어)를 이용하여 'sat'을 예측\n",
    "\n",
    "- 예측하려는 단어 : 중심 단어(center word)\n",
    "- 주변의 단어(중심 단어의 앞/뒤의 단어) : 주변 단어(context word)\n",
    "- 주변 단어의 범위 : window\n",
    "\n",
    "- CBOW 모델은 심층 신경망(Deep Neural Network)가 아닌 얕은 신경망(Shallow Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CBOW : 주변 단어로 중심 단어 예측\n",
    "- Skip-gram : 중심 단어로 주변 단어 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 영어 Word2Vec 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from lxml import etree\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve('https://wit3.fbk.eu/get.php?path=XML_releases/xml/ted_en-20160408.zip&filename=ted_en-20160408.zip', filename='ted_ed-20160408.zip')\n",
    "\n",
    "with zipfile.ZipFile('ted_ed-20160408.zip', 'r') as z:\n",
    "    target_text = etree.parse(z.open('ted_en-20160408.xml', 'r'))\n",
    "    parse_text = '\\n'.join(target_text.xpath('//content/text()'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here are two reasons companies fail: they only do more of the same, or they only do what's new.\\nTo me the real, real solution to quality growth is figuring out the balance between two activities: exploration and exploitation. Both are necessary, but it can be too much of a good thing.\\nConsider Facit\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_text[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n",
    "sent_text = sent_tokenize(content_text)\n",
    "\n",
    "normalized_text = []\n",
    "for string in sent_text:\n",
    "    tokens = re.sub(r'[^a-z0-9]+', ' ', string.lower())\n",
    "    normalized_text.append(tokens)\n",
    "    \n",
    "result = [word_tokenize(sentence) for sentence in normalized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플 수 : 273424\n"
     ]
    }
   ],
   "source": [
    "print('총 샘플 수 : {}'.format(len(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']\n",
      "['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation']\n",
      "['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing']\n"
     ]
    }
   ],
   "source": [
    "for line in result[:3]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=result, size=100, window=5, min_count=5, workers=4, sg=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- size : 워드 벡터의 특징, 임베딩된 벡터의 차원\n",
    "- window : 컨텍스트 윈도우 크기\n",
    "- min_count : 단어 최소 빈도 수 제한(빈도가 적은 단어들은 학습하지 않음)\n",
    "- workers : 학습을 위한 프로세스 수\n",
    "- sg : 0은 CBOW, 1은 Skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.8479523062705994), ('guy', 0.8010662794113159), ('lady', 0.7906370162963867), ('boy', 0.763181209564209), ('gentleman', 0.7517950534820557), ('soldier', 0.7506605386734009), ('girl', 0.726132869720459), ('kid', 0.7038574814796448), ('poet', 0.6737991571426392), ('son', 0.6676782369613647)]\n"
     ]
    }
   ],
   "source": [
    "model_result = model.wv.most_similar('man')\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('airplane', 0.7765852212905884), ('actor', 0.7602951526641846), ('ad', 0.7536124587059021), ('ipad', 0.7530655860900879), ('ambulance', 0.7458750009536743), ('app', 0.7428902983665466), ('athlete', 0.7344818115234375), ('asteroid', 0.7342614531517029), ('opera', 0.7341506481170654), ('f', 0.7328816652297974)]\n"
     ]
    }
   ],
   "source": [
    "model_result = model.wv.most_similar('apple')\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec 모델 저장 / 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('eng_w2v') # save\n",
    "loaded_model = KeyedVectors.load_word2vec_format('eng_w2v') # load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('airplane', 0.7765852212905884), ('actor', 0.7602951526641846), ('ad', 0.7536124587059021), ('ipad', 0.7530655860900879), ('ambulance', 0.7458750009536743), ('app', 0.7428902983665466), ('athlete', 0.7344818115234375), ('asteroid', 0.7342614531517029), ('opera', 0.7341506481170654), ('f', 0.7328816652297974)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\nlp\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model_result = loaded_model.wv.most_similar('apple')\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한글 word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 로드 / 이해 / 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt', filename='ratings.txt')\n",
    "train_data = pd.read_table('ratings.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
       "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
       "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 리뷰 개수 : 200000\n"
     ]
    }
   ],
   "source": [
    "print('전체 리뷰 개수 : {}'.format(len(train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.dropna(how='any')\n",
    "print(train_data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 리뷰 개수(null 제거) : 199992\n"
     ]
    }
   ],
   "source": [
    "print('전체 리뷰 개수(null 제거) : {}'.format(len(train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\nlp\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_data['document'] = train_data['document'].str.replace('[^ㄱ-하-|가-힣]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고지금다시봐도재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을배우는학생으로외국디자이너와그들이일군전통을통해발전해가는문화산업이부러웠는데사실우...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리시리즈는부터뉴까지버릴께하나도없음최고</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와연기가진짜개쩔구나지루할거라고생각했는데몰입해서봤다그래이런게진짜영화지</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개자욱한밤하늘에떠있는초승달같은영화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                  어릴때보고지금다시봐도재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을배우는학생으로외국디자이너와그들이일군전통을통해발전해가는문화산업이부러웠는데사실우...      1\n",
       "2   4655635                          폴리스스토리시리즈는부터뉴까지버릴께하나도없음최고      1\n",
       "3   9251303              와연기가진짜개쩔구나지루할거라고생각했는데몰입해서봤다그래이런게진짜영화지      1\n",
       "4  10067386                                안개자욱한밤하늘에떠있는초승달같은영화      1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['의', '가', '이', '은', '들', '는', '좀', '잘', '강', '과', '도', '를', '으로', '자', '에', '와', '하', '하다']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "tokenized_data = []\n",
    "for sentence in train_data['document']:\n",
    "    temp_X = okt.morphs(sentence, stem=True)\n",
    "    temp_X = [word for word in temp_X if not word in stopwords]\n",
    "    tokenized_data.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : <generator object <genexpr> at 0x000001FE16BED6C8>\n",
      "리뷰의 평균 길이 : 10.704148165926638\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('리뷰의 최대 길이 : {}'.format(max(len(l)) for l in tokenized_data))\n",
    "print('리뷰의 평균 길이 : {}'.format(sum(map(len,tokenized_data)) / len(tokenized_data)))\n",
    "plt.hist([len(s) for s in tokenized_data], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=tokenized_data, size=100, window=5, min_count=5, workers=4, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17962, 100)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('설경구', 0.8844647407531738), ('김혜수', 0.8839905858039856), ('한석규', 0.8825848698616028), ('이정재', 0.8769087195396423), ('류승범', 0.876903235912323), ('유해진', 0.8731832504272461), ('이준기', 0.8639912605285645), ('차승원', 0.863772988319397), ('최민수', 0.8634054660797119), ('디카프리오', 0.8623024225234985)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar('송강호'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('송해성', 0.9090892672538757), ('김두영', 0.9073273539543152), ('김청기', 0.9065903425216675), ('박철수', 0.9034940004348755), ('이창동', 0.9002180099487305), ('이준익', 0.8990355730056763), ('박찬욱', 0.8968294858932495), ('핀처', 0.8943756222724915), ('임권택', 0.8925238847732544), ('류승완', 0.8922854065895081)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar('봉준호'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
